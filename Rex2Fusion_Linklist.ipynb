{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title ðŸ› ï¸ Rex2Fusion_Linklist\n",
        "# @markdown Enter the Start Number and click **Play** (â–¶ï¸).\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# @markdown ### Settings\n",
        "Linklist_Start_Number = 50 # @param {type:\"integer\"}\n",
        "\n",
        "print(\"Waiting for file upload...\")\n",
        "\n",
        "# 1. Upload\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"âŒ No file uploaded.\")\n",
        "else:\n",
        "    start_time = time.time()\n",
        "    filename = next(iter(uploaded))\n",
        "    print(f\"\\nProcessing: {filename}...\")\n",
        "\n",
        "    # --- PART A: ROBUST READING ---\n",
        "    raw_data = uploaded[filename]\n",
        "    try:\n",
        "        content = raw_data.decode('utf-8-sig', errors='ignore')\n",
        "    except:\n",
        "        content = raw_data.decode('latin-1', errors='ignore')\n",
        "\n",
        "    content = content.replace('\\x00', '')\n",
        "    lines = content.splitlines()\n",
        "\n",
        "    # --- PART B: PARSE DATA ---\n",
        "    collections = []     # For File 1\n",
        "    unit_map = {}        # For File 1 (Linked Units)\n",
        "\n",
        "    # Structure for File 2: {id: 50, name: \"Hood\", units: [\"Code1\", \"Code2\"]}\n",
        "    parsed_collections = []\n",
        "\n",
        "    processing_id = Linklist_Start_Number\n",
        "\n",
        "    # Fast Regex Patterns\n",
        "    name_pattern = re.compile(r\"^#([^;]+)\")\n",
        "    code_pattern = re.compile(r\"#([^\\[;#]+)\\[([\\d\\.,]+)\\]\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line: continue\n",
        "\n",
        "        # 1. Collection Line\n",
        "        if line.startswith(\"#\"):\n",
        "            # Name\n",
        "            name_match = name_pattern.search(line)\n",
        "            coll_name = name_match.group(1).strip() if name_match else line.split(\";\")[0].replace(\"#\", \"\").strip()\n",
        "\n",
        "            # Codes\n",
        "            found_codes = code_pattern.findall(line)\n",
        "            coll_units = []\n",
        "\n",
        "            for code, qty_str in found_codes:\n",
        "                qty_str = qty_str.replace(\",\", \".\")\n",
        "                try:\n",
        "                    qty = float(qty_str)\n",
        "                    loop_count = int(qty) if qty.is_integer() else 1\n",
        "                except:\n",
        "                    loop_count = 1\n",
        "\n",
        "                # Expand rows for File 1\n",
        "                for _ in range(loop_count):\n",
        "                    collections.append({\n",
        "                        \"Linklist ID\": processing_id,\n",
        "                        \"Linklist Name\": coll_name,\n",
        "                        \"Linklist Units\": code.strip(),\n",
        "                        \"Number of Units\": \"[1.000]\",\n",
        "                        \"Series ID\": 0\n",
        "                    })\n",
        "                    # Add to list for File 2 (Linklist Import)\n",
        "                    coll_units.append(code.strip())\n",
        "\n",
        "            # Save structured data for File 2\n",
        "            parsed_collections.append({\n",
        "                \"id\": processing_id,\n",
        "                \"name\": coll_name,\n",
        "                \"units\": coll_units\n",
        "            })\n",
        "\n",
        "            processing_id += 1\n",
        "\n",
        "        # 2. Unit Line (for File 1 Linked Lists)\n",
        "        elif line.startswith(\";#\"):\n",
        "            unit_name = line.replace(\";\", \"\").replace(\"#\", \"\").strip()\n",
        "            if unit_name:\n",
        "                active_id = processing_id - 1\n",
        "                if unit_name not in unit_map: unit_map[unit_name] = []\n",
        "                unit_map[unit_name].append(active_id)\n",
        "\n",
        "    # --- PART C: GENERATE FILE 1 (Main Converted File) ---\n",
        "    print(\"-> Generating File 1...\")\n",
        "    df1 = pd.DataFrame(collections)\n",
        "    req_cols = [\"Linklist ID\", \"Linklist Name\", \"Linklist Units\", \"Number of Units\", \"Series ID\"]\n",
        "    for c in req_cols:\n",
        "        if c not in df1.columns: df1[c] = \"\"\n",
        "\n",
        "    unit_data_list = []\n",
        "    for u_name, id_list in unit_map.items():\n",
        "        link_str = \"<\"\n",
        "        for idx, linked_id in enumerate(id_list):\n",
        "            link_str += f\"{idx+1}~1~{linked_id}|\"\n",
        "        link_str += \">\"\n",
        "        unit_data_list.append({\"Unit Name\": u_name, \"Linked Lists\": link_str})\n",
        "\n",
        "    df1_units = pd.DataFrame(unit_data_list)\n",
        "    df1_final = pd.concat([df1.reset_index(drop=True), df1_units.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    final_cols_1 = [\"Linklist ID\", \"Linklist Name\", \"Linklist Units\", \"Number of Units\", \"Series ID\", \"Unit Name\", \"Linked Lists\"]\n",
        "    for c in final_cols_1:\n",
        "        if c not in df1_final.columns: df1_final[c] = \"\"\n",
        "    df1_final = df1_final[final_cols_1].fillna(\"\")\n",
        "\n",
        "    # --- PART D: GENERATE FILE 2 (Import_Linklist) ---\n",
        "    print(\"-> Generating File 2...\")\n",
        "    tab2_rows = []\n",
        "\n",
        "    # Static Values Reference (Row 2 of your sample)\n",
        "    static_vals = {\n",
        "        \"Add OR Delete\": \"A\",\n",
        "        \"Series ID\": 0, \"Catalogue ID\": 0, \"Use Unit Dims\": True,\n",
        "        \"UDX\": 0, \"UDY\": 0, \"UDZ\": 0, \"Use Unit Cursor Moves\": True,\n",
        "        \"PREDISTX:\": 0, \"PREMETHODX:\": \"SpecifiedDist\",\n",
        "        \"PREDISTY:\": 0, \"PREMETHODY:\": \"SpecifiedDist\",\n",
        "        \"PREDISTZ:\": 0, \"PREMETHODZ:\": \"SpecifiedDist\", \"PREROT:\": 0,\n",
        "        \"POSTDISTX:\": 0, \"POSTMETHOSX:\": \"UnitDistPos\",\n",
        "        \"POSTDISTY:\": 0, \"POSTMETHODSTY:\": \"SpecifiedDist\",\n",
        "        \"POSTDISTZ:\": 0, \"POSTMETHODZ:\": \"SpecifiedDist\", \"POSTROT\": 0,\n",
        "        \"Clash With Parent\": False, \"Handing\": \"None\", \"Status\": \"Compulsory\",\n",
        "        \"Lock Linked Unit Attributes\": True\n",
        "    }\n",
        "\n",
        "    for col_data in parsed_collections:\n",
        "        c_id = col_data[\"id\"]\n",
        "        c_name = col_data[\"name\"]\n",
        "        units = col_data[\"units\"]\n",
        "\n",
        "        for i, u_code in enumerate(units):\n",
        "            row = static_vals.copy()\n",
        "            row[\"Link List ID\"] = c_id\n",
        "            row[\"Link List Name\"] = c_name\n",
        "            row[\"Unit Number\"] = i + 1\n",
        "            row[\"UnitName\"] = u_code\n",
        "            tab2_rows.append(row)\n",
        "\n",
        "    df2_final = pd.DataFrame(tab2_rows)\n",
        "\n",
        "    # Ordered Headers\n",
        "    tab2_cols = [\n",
        "        \"Add OR Delete\", \"Link List ID\", \"Link List Name\", \"Unit Number\", \"UnitName\",\n",
        "        \"Series ID\", \"Catalogue ID\", \"Use Unit Dims\", \"UDX\", \"UDY\", \"UDZ\",\n",
        "        \"Use Unit Cursor Moves\", \"PREDISTX:\", \"PREMETHODX:\", \"PREDISTY:\",\n",
        "        \"PREMETHODY:\", \"PREDISTZ:\", \"PREMETHODZ:\", \"PREROT:\", \"POSTDISTX:\",\n",
        "        \"POSTMETHOSX:\", \"POSTDISTY:\", \"POSTMETHODSTY:\", \"POSTDISTZ:\",\n",
        "        \"POSTMETHODZ:\", \"POSTROT\", \"Clash With Parent\", \"Handing\",\n",
        "        \"Status\", \"Lock Linked Unit Attributes\"\n",
        "    ]\n",
        "    for c in tab2_cols:\n",
        "        if c not in df2_final.columns: df2_final[c] = \"\"\n",
        "    df2_final = df2_final[tab2_cols]\n",
        "\n",
        "    # --- PART E: DOWNLOAD ---\n",
        "    base_name = os.path.splitext(filename)[0]\n",
        "    file1_name = f\"{base_name}_CopyLinklist.xlsx\"\n",
        "    file2_name = f\"{base_name}_Import_Linklist.xlsx\"\n",
        "\n",
        "    print(f\"âœ… Saving {file1_name}...\")\n",
        "    df1_final.to_excel(file1_name, index=False)\n",
        "\n",
        "    print(f\"âœ… Saving {file2_name}...\")\n",
        "    df2_final.to_excel(file2_name, index=False)\n",
        "\n",
        "    print(f\"\\nDownloading both files...\")\n",
        "    files.download(file1_name)\n",
        "    files.download(file2_name)\n",
        "\n",
        "    print(f\"Done! (Total time: {round(time.time() - start_time, 2)}s)\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oxfLIlfyrTPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}